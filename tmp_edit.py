from pathlib import Path
import math
path = Path("cto10r/mining.py")
text = path.read_text()
start = text.index("def mine_rules")
end = text.index("    return {\"promoted\": promoted_full}\n", start) + len("    return {\"promoted\": promoted_full}\n")
new_func = """def mine_rules(cands: pd.DataFrame, events: pd.DataFrame, cfg: dict):\n    \"\"\"Mine high-precision rules using Wilson LCB and per-month consistency.\"\"\"\n    rules_cfg = (cfg.get(\"rules\") or {})\n    features_cfg = (cfg.get(\"features\") or {})\n    out_dir = Path(cfg.get(\"out_dir\", \".\"))\n    artifacts_dir = ensure_artifacts(out_dir)\n\n    join_cols = [\"ts\", \"side\", \"entry\", \"level\", \"risk_dist\"]\n    df = cands.merge(events, on=join_cols, how=\"inner\", suffixes=(\"\", \"\"))\n    if \"ym\" not in df.columns:\n        ts_series = pd.to_numeric(df[\"ts\"], errors=\"coerce\")\n        df[\"ym\"] = pd.to_datetime(ts_series, unit=\"ms\", errors=\"coerce\").dt.to_period(\"M\").astype(str)\n\n    if len(df) == 0:\n        (artifacts_dir / \"gating.json\").write_text(json.dumps({\"promoted\": []}, indent=2))\n        cols = [\n            \"rule_id\",\n            \"support_n\",\n            \"wins\",\n            \"losses\",\n            \"timeouts\",\n            \"precision\",\n            \"precision_lcb\",\n            \"lift\",\n            \"lift_lcb\",\n            \"months_with_lift\",\n            \"unique_months\",\n        ]\n        pd.DataFrame(columns=cols).to_csv(artifacts_dir / \"rules_eval.csv\", index=False)\n        return {\"promoted\": []}\n\n    df = df.copy()\n    df[\"is_win\"] = (df[\"outcome\"] == \"win\").astype(int)\n    df[\"is_loss\"] = (df[\"outcome\"] == \"loss\").astype(int)\n    df[\"is_to\"] = (df[\"outcome\"] == \"timeout\").astype(int)\n\n    include_timeouts = bool(rules_cfg.get(\"precision_include_timeouts\", False))\n    if include_timeouts:\n        base_n = int(len(df))\n    else:\n        base_n = int((df[\"is_win\"] + df[\"is_loss\"]).sum())\n    base_k = int(df[\"is_win\"].sum())\n    base_p = base_k / base_n if base_n > 0 else 0.0\n\n    auto = bool(rules_cfg.get(\"auto_binning\", True))\n    max_terms = max(1, int(rules_cfg.get(\"max_terms\", 2)))\n    metric_name = str(rules_cfg.get(\"metric\", \"precision_lcb\")).lower()\n    min_frac = float(rules_cfg.get(\"min_support_frac\", 0.0))\n    n_train = len(df)\n    min_support_n = max(int(math.ceil(min_frac * n_train)), 1) if n_train > 0 else 1\n    min_months = max(1, int(rules_cfg.get(\"min_months\", 1)))\n    min_wins = int(rules_cfg.get(\"min_wins\", 0))\n    uplift_abs = float(rules_cfg.get(\"min_precision_uplift_abs\", 0.0))\n    uplift_mul = float(rules_cfg.get(\"min_lift_lcb\", 0.0))\n    top_k = int(rules_cfg.get(\"top_k\", 25))\n    z_score = float(rules_cfg.get(\"wilson_z\", 1.96))\n\n    print(f\"[mining] auto_binning={auto} n_train={n_train} min_support={min_support_n}\", flush=True)\n\n    train_mask = np.ones(len(df), dtype=bool)\n    work = df.copy()\n    bcols: list[str] = []\n    bin_edges: dict[str, np.ndarray] = {}\n\n    if auto:\n        work, bcols = prepare_literal_buckets(df, train_mask, rules_cfg, features_cfg)\n        literal_cols = [c for c in sorted(bcols) if pd.to_numeric(work[c], errors=\"coerce\").notna().any()]\n    else:\n        feature_cols = [\n            \"t_240\",\n            \"t_60\",\n            \"t_15\",\n            \"accel_15_240\",\n            \"body_dom\",\n            \"atr_p\",\n            \"dcw_p\",\n            \"close_to_hi_atr\",\n            \"close_to_lo_atr\",\n        ]\n        feature_cols = [c for c in feature_cols if c in df.columns]\n        if not feature_cols:\n            (artifacts_dir / \"gating.json\").write_text(json.dumps({\"promoted\": []}, indent=2))\n            cols = [\n                \"rule_id\",\n                \"support_n\",\n                \"wins\",\n                \"losses\",\n                \"timeouts\",\n                \"precision\",\n                \"precision_lcb\",\n                \"lift\",\n                \"lift_lcb\",\n                \"months_with_lift\",\n                \"unique_months\",\n            ]\n            pd.DataFrame(columns=cols).to_csv(artifacts_dir / \"rules_eval.csv\", index=False)\n            return {\"promoted\": []}\n        bins_cfg = rules_cfg.get(\"bins\", {}) or {}\n        for feat in feature_cols:\n            if feat.startswith(\"t_\"):\n                edges_cfg = bins_cfg.get(\"t\", [])\n            elif feat == \"accel_15_240\":\n                edges_cfg = bins_cfg.get(\"accel\", [])\n            elif feat == \"body_dom\":\n                edges_cfg = bins_cfg.get(\"body_dom\", [])\n            elif feat in (\"atr_p\", \"dcw_p\"):\n                edges_cfg = bins_cfg.get(\"atr_p\", [])\n            else:\n                edges_cfg = bins_cfg.get(\"close_to_ext_atr\", [])\n            edges = [-np.inf] + list(edges_cfg) + [np.inf]\n            bin_edges[feat] = np.array(edges, dtype=float)\n            values = pd.to_numeric(work[feat], errors=\"coerce\")\n            bvals = np.full(len(values), np.nan)\n            mask_vals = values.notna()\n            if mask_vals.any():\n                bvals[mask_vals] = np.digitize(values[mask_vals], bin_edges[feat], right=True)\n            work[f\"B_{feat}\"] = bvals\n        literal_cols = [f\"B_{feat}\" for feat in feature_cols if pd.notna(work[f\"B_{feat}\"]).any()]\n\n    if not literal_cols:\n        (artifacts_dir / \"gating.json\").write_text(json.dumps({\"promoted\": []}, indent=2))\n        cols = [\n            \"rule_id\",\n            \"support_n\",\n            \"wins\",\n            \"losses\",\n            \"timeouts\",\n            \"precision\",\n            \"precision_lcb\",\n            \"lift\",\n            \"lift_lcb\",\n            \"months_with_lift\",\n            \"unique_months\",\n        ]\n        pd.DataFrame(columns=cols).to_csv(artifacts_dir / \"rules_eval.csv\", index=False)\n        return {\"promoted\": []}\n\n    rule_stats: dict[str, dict] = {}\n    rule_payload: dict[str, dict] = {}\n\n    def register_rule(rule_id: str, conds: list[dict], sub: pd.DataFrame):\n        n, wins, losses, tos = rule_precision_counts(sub, include_timeouts)\n        if n < min_support_n:\n            return\n        if wins < min_wins:\n            return\n        unique_months = int(sub[\"ym\"].nunique()) if \"ym\" in sub.columns else 1\n        if unique_months < min_months:\n            return\n        p_hat = wins / n if n else 0.0\n        p_lcb = wilson_lcb(wins, n, z=z_score)\n        if base_p > 0:\n            lift = p_hat / base_p\n            lift_lcb = p_lcb / base_p\n        else:\n            lift = float(\"inf\") if p_hat > 0 else 0.0\n            lift_lcb = float(\"inf\") if p_lcb > 0 else 0.0\n\n        months_with_lift = 0\n        if \"ym\" in sub.columns:\n            bym = sub.groupby(\"ym\").agg(\n                n=(\"is_win\", \"size\"), win=(\"is_win\", \"sum\"), loss=(\"is_loss\", \"sum\"), to=(\"is_to\", \"sum\")\n            ).reset_index()\n            if include_timeouts:\n                denom = bym[\"n\"].astype(float).replace(0.0, np.nan)\n            else:\n                denom = (bym[\"win\"] + bym[\"loss\"]).astype(float).replace(0.0, np.nan)\n            probs = bym[\"win\"] / denom\n            if base_p > 0:\n                months_with_lift = int((probs > base_p).sum())\n            else:\n                months_with_lift = int((bym[\"win\"] > 0).sum())\n        metrics = {\n            \"rule_id\": rule_id,\n            \"support_n\": int(n),\n            \"wins\": int(wins),\n            \"losses\": int(losses),\n            \"timeouts\": int(tos),\n            \"precision\": float(p_hat),\n            \"precision_lcb\": float(p_lcb),\n            \"lift\": float(lift),\n            \"lift_lcb\": float(lift_lcb),\n            \"months_with_lift\": int(months_with_lift),\n            \"unique_months\": int(unique_months),\n        }\n        existing = rule_stats.get(rule_id)\n        replace = False\n        if existing is None:\n            replace = True\n        else:\n            if metrics[\"precision_lcb\"] > existing[\"precision_lcb\"]:\n                replace = True\n            elif metrics[\"precision_lcb\"] == existing[\"precision_lcb\"] and metrics[\"support_n\"] > existing[\"support_n\"]:\n                replace = True\n        if replace:\n            rule_stats[rule_id] = metrics\n            rule_payload[rule_id] = {\n                \"rule_id\": rule_id,\n                \"conds\": conds,\n                \"precision\": metrics[\"precision\"],\n                \"precision_lcb\": metrics[\"precision_lcb\"],\n                \"support_n\": metrics[\"support_n\"],\n                \"wins\": metrics[\"wins\"],\n                \"losses\": metrics[\"losses\"],\n                \"timeouts\": metrics[\"timeouts\"],\n                \"lift\": metrics[\"lift\"],\n                \"lift_lcb\": metrics[\"lift_lcb\"],\n                \"unique_months\": metrics[\"unique_months\"],\n                \"months_with_lift\": metrics[\"months_with_lift\"],\n            }\n\n    if auto:\n        for col in literal_cols:\n            mask_col = work[col].notna()\n            if not mask_col.any():\n                continue\n            for val, sub in work[mask_col].groupby(col, observed=True):\n                conds = [{\"feat\": col, \"op\": \"==\", \"thr\": float(val)}]\n                register_rule(canonical_rule_id(conds), conds, sub)\n        if max_terms >= 2:\n            for i in range(len(literal_cols)):\n                col_i = literal_cols[i]\n                for j in range(i + 1, len(literal_cols)):\n                    col_j = literal_cols[j]\n                    if col_i == col_j:\n                        continue\n                    mask_pair = work[col_i].notna() & work[col_j].notna()\n                    if not mask_pair.any():\n                        continue\n                    for (val_i, val_j), sub in work[mask_pair].groupby([col_i, col_j], observed=True):\n                        conds = [\n                            {\"feat\": col_i, \"op\": \"==\", \"thr\": float(val_i)},\n                            {\"feat\": col_j, \"op\": \"==\", \"thr\": float(val_j)},\n                        ]\n                        register_rule(canonical_rule_id(conds), conds, sub)\n    else:\n        feature_cols = [col[2:] for col in literal_cols]\n        for feat, col in zip(feature_cols, literal_cols):\n            mask_col = work[col].notna()\n            if not mask_col.any():\n                continue\n            for val, sub in work[mask_col].groupby(col, observed=True):\n                conds = bin_to_conditions(feat, val, bin_edges[feat])\n                if not conds:\n                    continue\n                register_rule(canonical_rule_id(conds), conds, sub)\n        if max_terms >= 2:\n            for i in range(len(feature_cols)):\n                feat_i = feature_cols[i]\n                col_i = literal_cols[i]\n                for j in range(i + 1, len(feature_cols)):\n                    feat_j = feature_cols[j]\n                    col_j = literal_cols[j]\n                    mask_pair = work[col_i].notna() & work[col_j].notna()\n                    if not mask_pair.any():\n                        continue\n                    for (val_i, val_j), sub in work[mask_pair].groupby([col_i, col_j], observed=True):\n                        conds = bin_to_conditions(feat_i, val_i, bin_edges[feat_i]) + bin_to_conditions(feat_j, val_j, bin_edges[feat_j])\n                        if not conds:\n                            continue\n                        register_rule(canonical_rule_id(conds), conds, sub)\n\n    stats_cols = [\n        \"rule_id\",\n        \"support_n\",\n        \"wins\",\n        \"losses\",\n        \"timeouts\",\n        \"precision\",\n        \"precision_lcb\",\n        \"lift\",\n        \"lift_lcb\",\n        \"months_with_lift\",\n        \"unique_months\",\n    ]\n    if rule_stats:\n        stats = pd.DataFrame(rule_stats.values()).reindex(columns=stats_cols)\n    else:\n        stats = pd.DataFrame(columns=stats_cols)\n\n    metric_map = {\n        \"precision\": \"precision\",\n        \"precision_lcb\": \"precision_lcb\",\n        \"lift\": \"lift\",\n        \"lift_lcb\": \"lift_lcb\",\n        \"support\": \"support_n\",\n        \"support_n\": \"support_n\",\n    }\n    metric_col = metric_map.get(metric_name, \"precision_lcb\")\n    stats = stats.sort_values([metric_col, \"support_n\"], ascending=[False, False]).reset_index(drop=True)\n\n    prec_threshold = (base_p + uplift_abs) if base_p > 0 else uplift_abs\n    lift_threshold = max(uplift_mul, 0.0)\n    if not stats.empty:\n        promoted = stats[\n            (stats[\"precision_lcb\"] >= prec_threshold)\n            & (stats[\"lift_lcb\"] >= lift_threshold)\n        ].copy()\n        if min_wins > 0:\n            promoted = promoted[promoted[\"wins\"] >= min_wins]\n        promoted = promoted.head(top_k).reset_index(drop=True)\n    else:\n        promoted = stats.copy()\n\n    promoted_ids = promoted[\"rule_id\"].tolist() if not promoted.empty else []\n    promoted_full = [rule_payload[rid] for rid in promoted_ids if rid in rule_payload]\n\n    (artifacts_dir / \"gating.json\").write_text(json.dumps({\"promoted\": promoted_full}, indent=2))\n    stats.to_csv(artifacts_dir / \"rules_eval.csv\", index=False)\n\n    return {\"promoted\": promoted_full}\n"""\ntext = text[:start] + new_func + text[end:]
path.write_text(text)
